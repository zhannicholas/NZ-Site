---
date: "2021-03-19T22:36:40+08:00"
title: "内存虚拟化"
authors: ["zhannicholas"]
categories:
  - 读书笔记
tags:
  - OSTEP
draft: false
toc: true
mathjax: true
---

## 地址空间

操作系统为用户提供了一个易于使用的物理内存抽象，这个抽象叫做 **地址空间（address space）**。在系统中，地址空间是运行的程序看到的内存。

一个进程的地址空间包含运行的程序的所有内存状态。当程序运行时，利用栈（stack）保存当前的函数调用信息，分配空间给局部变量、传递参数和返回值。最后，堆（heap）用于管理动态分配的、由用户管理的内存。当然，还有其它的东西，比如静态初始化变量。不过我们现在可以假设地址空间只有三部分：代码、栈和堆。

![](/images/reading_notes/ostep/address-space-example.png)

上图展示了一个小型地址空间（只有 16KB）的例子。其中程序代码位于地址空间的顶部。在程序运行时，地址空间的堆（顶部）和栈（底部）两个区域可能动态增长或收缩。这种两端放置的方法只是一种约定，实际上可以按照任意方法放置。

当我们描述地址空间时，我们描述的是操作系统提供给运行程序的抽象。以上面 16KB 的地址空间为例，程序实际上可能处于物理内存中的任意位置，并不一定在 0-16KB之间。地址空间描述的是虚拟内存，它与物理内存是不同的。

> 关键问题：如何虚拟化内存？操作系统如何在单一的物理内存上为多个进程构建出一个私有的、可能无限大的地址空间的抽象？

隔离是建立可靠系统的关键原则。如果两个实体相互隔离，则一个实体的失败不会影星到另一个实体。操作系统尽力让进程之间彼此隔离，从而防止相互伤害。

## 虚拟化内存的目标

虚拟内存系统有几个重要的目标：

* 透明（transparency）：运行的程序并不会感知到内存被虚拟化的事实，程序的行为就好像它拥有自己的私有物理内存。背后是操作系统的辛勤工作，操作系统让不同的任务复用内存，从而提供这个假象。
* 效率（efficiency）：操作系统应该让虚拟化尽可能地高效。为此，可能需要像 TLB 这样的硬件支持。
* 保护（protection）：操作系统应当确保进程和自己受到保护，不受其它进程影响。保护让我们能够在进程之间提供隔离的特性，避免恶意进程的破坏。保护让我们能够在进程之间提供隔离机制，每个进程都应该在自己独立的环境中运行，避免其它出错或恶意进程的影响。

> C 程序里面可以打印指针，但是我们看到的值是虚拟地址而不是物理地址（我们看到的所有地址都不是真的）。虚拟地址只是提供地址如何在内存中分布的假象，只有操作系统（和硬件）知道物理地址。这也反映出了用户程序和操作系统看到东西的不同。

## 地址转换

前面提到过，运行中的程序看到的是虚拟地址，而数据是位于物理地址中的。为了读取正确的数据，需要进行虚拟地址到物理地址的转换。

基于硬件的地址转换（hardware-based address translation）简称地址转换（address translation），它是一种通用技术。每当程序进行内存访问（取指令、读写数据）时，地址转换将指令中的虚拟地址（virtual address）转换为实际的物理地址（physical address）。因此，在每次内存引用时，硬件都会进行地址转换，将应用程序的内存引用重定位到内存中的实际位置。

仅靠硬件不足以实现虚拟内存，硬件只是提供了底层机制来提高地址转换的效率，实现虚拟内存还需要操作系统在关键位置介入。因此，操作系统必须能够管理内存，记录内存的使用情况。

> **介入（interposiiton）** 是一种很常见又很有用的技术。在虚拟内存中，硬件可以介入到每次内存访问中，将进程提供的虚拟地址转换为数据实际所在的物理地址。

## 动态（基于硬件）重定位

基于硬件的地址转换在早期的时候很简单：每个 CPU 需要两个硬件寄存器——**基址（base）寄存器** 和 **界限（bound）寄存器**，界限寄存器有时又称限制（limit）寄存器。二者的合作能保证地址空间在物理内存中的任何位置，同时确保进程只能访问自己的地址空间。

当我们编写和编译程序时，假设地址空间从零开始。但是，当程序真正执行时，操作系统会决定其在物理内存中的实际地址，并将基址寄存器设置为这个值。当进程运行时，硬件会通过以下方式计算出物理地址并发给内存系统：

$$ physical\ address = virtual\ address + base $$

地址转换技术指的正是将虚拟地址转换为物理地址。硬件取得进程认为它要访问的地址，将其转换为数据实际位于的物理地址，由于这种重定位是在运行时发生的，所以这种技术一般被称为动态重定位（dynamic relocation）。

基址寄存器负责支持重定位，而界限寄存器就负责提供内存保护，确保进程产生的地址都在进程应该处于的界限之中。界限寄存器通常有两种工作方式：

* 记录地址空间的大小，在硬件将虚拟地址与基址寄存器内容求和前检查这个界限。
* 记录地址空间结束的物理地址，在硬件将虚拟地址转换成物理地址之后去检查这个界限。

下面是一个例子。假设一个进程拥有 4KB 大小的地址空间，它被加载到从 16KB 开始的物理内存中，一些地址转换结果如下表所示：

| 虚拟地址 |      | 物理地址     |
| -------- | ---- | ------------ |
| 0        | →    | 16KB         |
| 1KB      | →    | 17KB         |
| 3000     | →    | 19384        |
| 4400     | →    | 错误（越界） |

### 操作系统的职责

为了支持动态重定位，操作系统需要处理一些问题：

* 内存管理
  - 为新进程分配内存
  - 从终止进程回收内存
  - 管理内存使用情况
* 基址/界限管理
  - 必须在上下文切换时正确设置基址/界限寄存器
* 异常处理
  - 当异常发生时执行必要的处理逻辑

## 分段

如果简单地将进程的整个地址空间放入物理内存，栈和堆之间的空间即使没有被使用，也会占用实际的物理内存。因此，简单地通过基址寄存器和界限寄存器实现的虚拟内存非常浪费。

分段（segmentation）实际上是为了支持更大的地址空间。其思想是：让地址空间内的每个逻辑段都有一对基址和界限寄存器。一个段（segment）只是地址空间内的一个连续定长的区域。在典型的地址空间里有3种不同的逻辑段：代码段、栈和堆。分段可以让操作系统将不同的段放到不同的物理内存区域，从而避免虚拟地址空间中未使用的部分占用物理内存。

段错误是指在支持分段的机器上发生了非法的内存访问。

当硬件在地址转换时使用段寄存器时，它如何知道虚拟地址引用了那个段，以及段内偏移量呢？一种常见的方式是用虚拟地址的前几位来标识不同的段，剩余位用来标识偏移量。这种方式显式地给出段的位置，硬件可以通过隐式方式获知。例如，如果地址由程序计数器产生，那么地址位于代码段，如果地址基于栈或者基址指针，那么地址位于栈段，其它情况则位于堆段。

## 空闲空间管理

**外部碎片（external fragmentation）**：空闲空间被分割成不同大小的小块，成为碎片，后续的内存分配请求会由于找不到一块足够大的连续空闲空间而失败，即使这时总的空闲空间超出了请求的大小。
**内部碎片（internal fragmentation）**：如果分配程序分配给程序的内存块超过了请求的大小，那么超出大小的部分（未被使用）就会称为内部碎片，即空间的浪费出现在已分配单元的内部。

空闲链表（free list）是一种管理空闲空间的数据结构，该结构包含了所管理内存区域中所有空闲块的引用。

常见的内存分配策略有：最优匹配、最差匹配、首次匹配、下次匹配等

**分离空闲链表**：如果某个程序经常申请一种或集中大小的内存空间，那就用一个独立的列表来管理这些大小的对象，其它大小的请求交给通用的内存分配程序。例如 Solaris 的内存分配程序厚块分配程序（slab allocator）。


## 分页

在内存管理方面，操作系统通常有两种方法：

* 分段：将空间分割成不同长度的分片，就像虚拟内存管理中的分段。但是，将空间切成不同长度的碎片后，空间本身会碎片化，随着时间的推移，分配内存会变得比较困难。
* 分页：将空间分割成固定长度的分片。每个分片为一个单元，即一页，称之为页帧（page frame）。

### 页表

为了记录地址空间的每个虚拟页在物理内存中所处的位置，操作系统通常会为每个进程保存一个被称为页表（page table）的数据结构。页表的主要作用是为每个虚拟页面保存地址转换信息，从而让我们知道每个页在物理内存中的位置。

虚拟地址由两部分组成：虚拟页面号（virtual page number，VPN）和页内偏移量（offset）。

![](/images/reading_notes/ostep/virtual-address.png)

在进行地址转换时，先根据 VPN 检索页表，找出虚拟页号对应的物理帧号（PFN）或物理页号（PPN）。通过用 PFN 替换 VPN 转换虚拟地址，页内偏移保持不变（虚拟页和物理页大小相等），过程如下：

![](/images/reading_notes/ostep/address-translation-process.png)

#### 页表的保存

页表可以变得非常大，一个 20 位的 VPN 意味着操作系统必须为每个进程管理 1M （大约一百万）个地址转换。假设每个页表条目（PTE）占 4B，则每个页表就需要 4MB 的存储空间。实际上，操作系统将每个进程的页表存储在内存中，由于很多操作系统内存本身也可以被虚拟化，所以页表也可以存储在操作系统的虚拟内存中（甚至可以被交换到磁盘上）。

### 分页的问题

普通的分页存在两个问题：

* 页表太大，导致访问慢。
* 页表太大，导致消耗的内存太多。

### TLB

TLB 是为了解决分页速度慢的问题。

基于分页的虚拟内存可能会带来比较高的性能开销，因为需要将地址空间切分为固定大小的页，并记录这些页的地址映射信息。由于这些信息一般存储在物理内存中，所以在进行地址转换时，分页逻辑需要一次额外的内存访问。每次获取指令、加载或保存数据，都需要多读一次内存才能得到转换信息，这回使得总体的慢难以接受。为了加速地址转换，操作系统需要硬件的帮助，也就是所谓的 **地址转换旁路缓冲（translation-lookaside buffer，TLB）**。

对于每次内存访问，硬件都会先检查 TLB，若其中包含期望的地址转换，则不需要访问页表就能完成转换。页表中包含全部的转换映射，直接走 TLB 而不查询页表会很快，TLB 因此能够带来巨大的性能提升。

TLB 和其他缓存类似，前提都是在一般情况下，转换映射会在缓存中（即TLB命中）。若是如此，只需要增加少量开销就可以达到非常快的访问速度，因为 TLB 就在处理器附近。如果 TLB 未命中，就会产生很大的分页开销，必须访问页表获取转换映射，导致额外的内存访问。如果经常这样，程序的运行就会显著变慢。因此，我们希望尽可能地避免 TLB 不命中。

既然缓存这么快，为什么不把它做得更大呢？原因是如果想要快速地缓存，它就必须小，因为光速和其它物理限制会起作用。大的缓存注定慢，因此无法实现目的。所以我们应该关注如何利用好缓存来提高性能。

随机存取存储器（Random-Access Memory，RAM）暗示你访问 RAM 的任意部分都一样快。虽然 一般这样想 RAM 没错，但因为 TLB 这样的硬件/操作系统功能，访问某些内存页的开销较大，尤其是 没有被 TLB 缓存的页。因此，最好记住这个实现的窍门：**RAM 不总是 RAM**。有时候随机访问地址空 间，尤其是 TLB 没有缓存的页，可能导致严重的性能损失。

### 较小的页表

> 关键问题：简单的线性页表太大，占用过多内存，如何让它更小？

一种方法是使用更大的页，页的数量少了，页表因此变小。但是，更大的页容易出现内部碎片，造成内存的浪费。

另一种方法是混合使用分段和分页方法，每个分段一个页表。但这避不开分段可能导致的外部碎片问题。

还有一种方法是采用多级页表。多级页表是时间与空间的折中。

在反向页表中，只有一个页表，其中的项代表系统的每个物理页，而不是进程的页表。页表项告诉我们哪个进程正在使用此页，以及该进程的哪个虚拟页映射到了此物理页。

## 交换

> 关键问题：操作系统如何利用大而慢的设备，透明地提供巨大虚拟地址空间的假象？

### 交换空间

为了提供巨大虚拟地址空间的假象，我们可以在硬盘上开辟一部分空间（交换空间，swap space）用于物理页的移入和移出。在必要的时候将内存中的页面交换出去，在需要的时候又从其中交换回来。

需要注意的是，交换空间不是唯一的硬盘交换目的地。

### 交换时机

操作系统一般会预留一小部分空闲内存。大多数操作系统都会设置高水位线（High Watermark，HW）和低水位线（Low Watermark，LW），从而帮助决定何时从内存中清楚页。原理很简单：当操作系统发现有少于 LW 个页可用时，后台负责释放内存的线程就会开始运行，直到有 HW 个可用物理页。

### 页置换策略

内存其实只包含了系统中所有页的子集，所以我们可以将其视为系统中虚拟内存页的缓存。从磁盘获取页就是缓存未命中，从内存中找到待访问的页就是缓存命中。

最优替换策略：替换内存中在最远将来才会被访问到的页，这样能达到最低的缓存命中率。

FIFO：先入先出替换策略。

随机策略：在内存满的时候随机选择一个页进行替换。

LRU（Least-Recently-Used）：替换最近使用最少的页面。

LFU（Least-Frequently-Used）：替换最近嘴部经常使用的页面。


抖动（trashing）：当内存被超额请求时，操作系统将会不断地进行换页。

