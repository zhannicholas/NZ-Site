---
date: "2021-03-15T21:28:39+08:00"
title: "CPU 虚拟化"
authors: ["zhannicholas"]
mathjax: true
categories:
  - 读书笔记
tags:
  - OSTEP
draft: false
toc: true
---

## 进程

进程即运行中的程序。程序本身是没有生命周期的，它只是存在磁盘上的一些指令（也可能是一些静态数据）。事实表明，人们通常希望同时运行多个程序。

> 关键问题：如何提供有许多 CPU 的假象？

操作系统通过 CPU 虚拟化提供有许多 CPU 的假象，允许一个进程运行一段时间，然后切换到其它进程，这就是时分共享（time sharing）技术。时分共享的潜在缺点就是性能损失，因为如果 CPU 必须共享，那么每个进程的运行就会慢一点。

要实现好 CPU 虚拟化，操作系统需要一些底层机制（mechanism）和高级策略（policy）。底层机制是一些底层方法或协议，实现了所需的功能，比如上下文切换（context switch）。而高级策略则是在操作系统内做出某种决定的算法，比如调度策略。

操作系统为正在运行的程序提供的抽象，就是所谓的进程（process）。要理解构成进程的是什么，我们必须理解进程的机器状态（machine state）：程序在运行时可以读取或更新的内容。内存是进程的机器状态的一个重要组成部分，指令位于内存中，程序读写的数据也在内存中；进程的机器状态的另一部分是寄存器；由于程序经常访问持久存储设备，此类 I/O 信息可能包含当前打开的文件列表。

### 进程的创建

> 操作系统如何将程序转化为进程？

![](/images/reading_notes/ostep/from-program-to-process.png)

要将程序转化为进程，操作系统需要完成以下工作：

1. 将代码和所有静态数据加载到内存中，加载到进程的地址空间中。
2. 为程序的运行时栈分配一些内存。C 语言中的栈用于存放局部变量、函数参数和返回地址。
3. 操作系统也可能为程序的堆分配一些内存。C 语言中的堆用于显式请求的动态分配数据。
4. 执行其它初始化任务，特别是与 I/O 相关的任务。
5. 启动程序。OS 将 CPU 的控制转转交给新创建的进程，程序开始运行。

### 进程状态

早期的计算机系统中，进程可以处于以下三种状态之一：

* 运行（running）：进程正在处理器上运行，这意味着进程正在执行指令。
* 就绪（ready）。进程已经准备好，但由于某些原因，操作系统选择不在此时运行该进程。
* 阻塞（blocked）：进程等待特定事件发生时才会准备运行，比如等待 I/O 完成。

### 进程的数据结构

操作系统也是一个程序，和其它程序一样，它维护了一些关键的数据结构，用来跟踪各种相关的信息。例如，下面是 xv6 内核中的进程结构：

```c
// the registers xv6 will save and restore 
// to stop and subsequently restart a process 
struct context { 
  int eip; 
  int esp; 
  int ebx; 
  int ecx; 
  int edx; 
  int esi; 
  int edi; 
  int ebp; 
}; 
// the different states a process can be in 
enum proc_state { UNUSED, EMBRYO, SLEEPING,
                  RUNNABLE, RUNNING, ZOMBIE }; 

// the information xv6 tracks about each process 
// including its register context and state 
struct proc { 
  char *mem;                  // Start of process memory 
  uint sz;                    // Size of process memory 
  char *kstack;               // Bottom of kernel stack for this process 
  enum proc_state state;      // Process state 
  int pid;                    // Process ID 
  struct proc *parent;        // Parent process 
  void *chan;                 // If !zero, sleeping on chan 
  int killed;                 // If !zero, has been killed 
  struct file *ofile[NOFILE]; // Open files 
  struct inode *cwd;          // Current directory 
  struct context context;     // Switch here to run process 
  struct trapframe *tf;       // Trap frame for the current interrupt 
}; 
```

## Limited Direct Execution

操作系统通过虚拟化 CPU 让多个任务共享物理 CPU，但是在构建这样的虚拟化时存在一些挑战：其一是性能，其二是控制权。控制权对于操作系统尤为重要，因为操作系统负责资源管理。操作系统应以高性能的方式虚拟化 CPU，同时保持对系统的控制。

> 关键问题：如何高效、可控地虚拟化 CPU？

受限直接执行（Limited Direct Execution）是操作系统开发人员想出的一种技术，目的是让程序尽可能快地运行。“受限”表示操作系统需要具备控制权，进程会受到一定的限制，“直接执行”就表示在 CPU 上运行程序。

### 受限制的操作

直接执行有一个明显的优势——快速，但是我们需要考虑当进程希望执行某种受限操作时（比如磁盘 I/O）该怎么办？

> 关键问题：如何执行受限制的操作？进程必须能够执行I/O等受限操作，但又不能完全让进程控制系统。

#### 用户模式与内核模式

操作系统与硬件协作，硬件提供不同的执行模式。在 **用户模式（user mode）** 下，应用程序不能访问全部的硬件资源，而在 **内核模式（kernel mode）** 下，操作系统可以访问机器的全部资源。

在用户模式下，运行的代码会受到限制。在内核模式下，运行的代码可以做任何事，操作系统（或内核）就运行在这个模式下。

系统调用允许内核向用户程序暴露某些关键功能，要执行系统调用，程序必须执行特殊的 **陷阱（trap）** 指令。该指令同时跳入内核并将特权级别提升到内核模式。系统调用执行完成后，操作系统调用一个特殊的 **从陷阱返回（return-from-trap）** 指令，返回到发起调用的用户程序中，同时将特权级别降低，回到用户模式。

在执行陷阱时，硬件必须确保保存足够的调用者寄存器，以便在操作系统发出从陷阱返回指令时能正确地返回。那么陷阱如何知道在 OS 内运行哪些代码呢？内核通过在启动时设置 **陷阱表（trap table）** 来呈现需要在 OS 内运行的代码。操作系统启动时做的有一件事情就是告诉硬件在发生某些异常事件时要运行哪些代码。

下面的时间线对首先直接运行协议进行了总结。整个过程假设每个进程都有一个内核栈，在进入内核时保存寄存器内容，在离开内核时恢复寄存器内容。

![LDE protocol](/images/reading_notes/ostep/lde-protocol.png)

LDE 协议有两个阶段。第一个阶段（在系统引导时），内核初始化陷阱表，并且 CPU 记住它的位置以供随后使用。内核通过特权指令来执行此操作（所有特权指令均以粗体突出显示）。第二个阶段（运行进程时），在使用从陷阱返回指令开始执行进程之前，内核设置了一些内容（例如，在进程列表中分配一个节点，分配内存）。这会将 CPU 切换到用户模式并开始运行该进程。当进程希望发出系统调用时，它会重新陷入操作系统，然后再次通过从陷阱返回，将控制权还给进程。该进程然后完成它的工作，并从 main()返回。这通常会返回到一些存根代码，它将正确退出该程序（例如，通过调用 exit()系统调用，这将陷入 OS 中）。此时，OS 清理干净，任务完成了。

### 进程切换

> 关键问题：操作系统如何重获 CPU 的控制权，以便它可以在进程间切换？

#### 协作方式

过去某些系统采用了一种被称为协作（cooperative）的方式，在这种方式下，操作系统相信进程会合理运行，运行时间过程的进程会定期放弃 CPU（通过系统调用），以便操作系统运行其它任务。

通常情况下，操作系统必须处理系统中的不当行为，如果某些进程执行了非法操作，操作系统需要重新控制 CPU。在协作方式中，某个进程若开启无限循环，并且不进行 yield 系统调用，那么操作系统则无法做任何事情。唯一的解决方式就是重启。

#### 非协作方式

通过 **时钟中断（timer interrupt）**，操作系统可以以非协作的方式获取 CPU 的控制权。时钟设备定时产生中断，产生中断时，当前运行的程序停止，操作系统预先配置的中断处理程序会运行。此时，操作系统重新获得 CPU 控制权，就可以做任何事情了，比如停止当前进程并启动另一个进程。

在发生中断时，硬件需要为当前正在运行的程序保存足够的状态，以便从陷阱返回指令能够正确恢复该程序。

**上下文切换（context switch）** ：操作系统要做的就是为当前正在执行的进程保存一些寄存器的值（例如，到它的内核栈），并为即将执行的进程恢复一些寄存器的值（从它的内核栈）。这样一来，操作系统就可以确保最后执行从陷阱返回指令时，不是返回到之前运行的进程，而是继续执行另一个进程。

下面是基于时钟的 LDE 协议：

![LDE protocol(time interrupt)](/images/reading_notes/ostep/lde-protocol-timer.png)

## 进程调度

> 关键问题：如何开发调度策略？什么是关键假设？哪些指标非常重要？

确定工作负载（workload）是构建调度策略的关键部分。工作负载了解得越多，你的调度策略就能越优化。此外，我们还需要一些调度指标，用来比较不同的调度策略。一个基本的调度指标是 **周转时间（turnround time）**。

任务的周转时间即任务完成时间减去任务到达系统的时间：

$$ T_{周转时间} = T_{完成时间} - T_{到达时间} $$

周转时间是一个性能指标。还有一个有趣的指标，它就是 **公平性（fairness）**。性能和公平性在调度系统中往往是矛盾的。

### 先进先出

先进先出（First In First Out，FIFO）调度是一种基本的算法，有时候又称为先来先服务（First Come First Service，FCFS）。FIFO 的调度思想是：先运行最先达到系统的任务，然后是第二到达的，以此类推。

![](/images/reading_notes/ostep/fifo.png)

假设 A、B、C 三个任务几乎同时到达系统（A 比 B 早一点点，B 比 C 早一点点），若采用 FIFO 调度策略，则调度器会先执行 A，然后执行 B，最后执行 C。从图 FIFO 1 可以看出：A 在 10s 完成，B 在 20 秒完成，C 在 30 秒完成。那么这三个任务的平均周转时间就是 $\frac {10 + 20 + 30}{30} = 20 $。但是，若三个任务的运行情况如图 FIFO 2 所示的话，三个任务的平均周转时间就是 $\frac {100 + 110 + 120}{3} = 110$。

第二种情况通常被成为 **护航效应（convoy effect）**，即一些耗时短较少的潜在资源消耗者排在重量级的资源消费者之后。这对于耗时较短的任务来说，并不友好。

### 最短任务优先

最短任务优先（Shortest Job First， SJF）是另一种调度算法，解决了 FIFO 算法中耗时较短的任务等待时间可能过长的问题。SJF 的调度思想是：先运行最短的任务，然后是词短的任务，以此类推。

![](/images/reading_notes/ostep/sjf.png)

假设 A、B、C 同时到达（图 SJF 1），按照 SJF 原则，系统会先运行 A，然后运行 B，最后运行 C。因此，SJF 可以将 110s 的平均周转时间降低到 $\frac {10 + 20 + 120}{3} = 50$。事实上，当所有任务同时到达系统时，SJF 被证明是一个最优的调度算法。但是 SJF 算法也存在问题，假设 A 先到达，10s 之后 B、C 也到达（图 SJF 2）了，三个任务的平均周转时间则是 $\frac {100 + (110 - 10) + (120 - 10)}{3} = 103.33$，仍然出现了护航效应。

### 最短完成时间优先

SJF 调度算法是非抢占式（non-preemptive），而最短完成时间优先（Shortest Time-to-Completion First，STCF）或抢占式最短作业优先（Preemptive Shortest Job First，PSJF）是 SJF 的抢占式版本。每当新任务进入系统时，调度程序就会计算剩余任务和新任务之间，哪个任务的剩余时间最短，然后调度该任务。

![](/images/reading_notes/ostep/stcf.png)

还是上一个例子，采用 STCF 算法，平均周转时间大大提高：$\frac {120 + (20 - 10) + (30 - 10)}{3} = 50$

### 轮转

周转时间关心的是任务完成的快慢，适合批处理系统。而在分时系统中，用户就在系统前面，期望系统具有良好的交互性。因此，新的调度指标——**响应时间（response time）** 出现了。响应时间指的是从任务到达系统到系统首次运行它的时间，即

$$T_{响应时间} = T_{首次运行} - T_{到达时间} $$

在 STCF 的例子中，周转时间很好，但是响应时间就没那么好了，如果用户在系统响应前不得不等待 10s,那就太糟糕了！现在思考新的问题，如何构建对响应时间敏感的程序？

有一种简单的调度算法，叫做轮转（Round-Robin，RR）。它的基本思想很简单：RR 在一个时间片内运行一个任务，然后切换至运行队列中的下一个任务，反复执行，直到所有任务完成。时间片（time slice）有时又称调度量子（scheduling quantum），需要注意的是：**时间片的长度必须是时钟中断周期的整数倍**。

![](/images/reading_notes/ostep/rr.png)

假设 A、B、C 三个任务同时到达系统，并且都希望运行 10s。SJF 调度程序必须在运行完当前任务之后才可运行下一个任务（图 RR 1），而 1s 的时间片可以让 RR 调度程序调度各任务快速地循环工作。SJF 的平均响应时间为：$\frac {0 + 10 + 20}{3} = 10$，而 RR 的平均响应时间为：$\frac {0 + 1 + 2}{3} = 1$。

可以发现，时间片长度 对 RR 至关重要。时间片越短，RR 在响应时间上的表现就越好。然而，时间片也不是越短越好：频繁的上下文切换将影响系统整体性能。因此，系统设计者需要衡量时间片的长度，设置一个足够长的值，以便在摊销（amortize）上下文切换成本的同时保持系统的响应性。

### 多级反馈队列

多级反馈队列（Multi-level Feedback Queue，MLFQ）是一种应用于兼容时分共享系统（Compatible Time-Sharing System）的调度算法。它有两个目标：其一是优化周转时间，其二是给用户良好的交互体验（降低响应时间）。

> 关键问题：没有工作长度的先验知识，如何设计一个能同时减少响应时间和周转时间的调度程序。

方法是 **从历史中学习**。MLFQ 就是用历史经验预测未来的一个典型例子。

MLFQ 中有许多独立的队列，每个队列有不同的优先级。任何时刻，一个任务只能存在于一个队列中。MLFQ 总是优先执行较高优先级的任务（在较高级队列中的任务）。当然，一个队列中可能会有多个任务（这些任务的优先级相同），这时可以对它们采用轮转调度。因此，MLFQ 调度策略的关键在于 **如何设置优先级**。 

#### 基本规则

MLFQ 的基本规则：

* 规则 1：If Priority(A) > Priority(B), A runs (B doesn't).
* 规则 2：If Priority(A) = Priority(B), A & B run in RR.
* 规则 3：When a job enters the system, it is placed at the highest priority (the topmost queue).
* 规则 4a：If a job uses up an entire time slice while running, its priority is reduced (i.e., it moves down one queue).
* 规则 4b：If a job gives up the CPU before the time slice is up, it stays at the same priority level.
* 规则 5：After some time period S, move all the jobs in the system to the topmost queue.

规则 1 和 规则 2 是最基本的两条规则，给出了两个任务在给定优先级下的执行顺序，会出现低优先级的任务饥饿的情况。

规则 3、4a、4b 给出了改变优先级的规则。它能够根据负载情况调整任务的优先级，使得耗时任务之间可以公平地共享 CPU，并且短任务或交互性任务也能得到很好的响应时间，但是仍然存在饥饿的问题——过多的交互任务会导致耗时任务饥饿。

规则 5 定时改变优先级，消除了饥饿，保证了任务的执行。但是引入的时间段 S 又带来了新的问题——S 该如何设置？太长会让耗时任务会饥饿，太短会让交互型任务得不到合适的 CPU 时间。

一个更好的计时方式是修改规则 4a、4b。让调度程序记录一个进程在某一个队列中消耗的总时间，而不是在调度时重新计时。只要进程用完了自己的配额，就把它降到低一优先级的队列中去。因此，重写规则 4a、4b 为规则 4：

* 规则 4：Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).

#### 与其它调度策略的不同

MLFQ 不同于 FCFS、SJF、STCF，它不需要对任务的运作方式有先验知识，而是通过观察任务的运行情况来给出对应的优先级。

MLFQ 可以满足各种任务需求：对运行时间短的交互型任务，它可以获得类似于 SJF/STCF 的较不错的全局性能，同时对于耗时的 CPU 密集型负载也可以公平地稳步向前。

### 比例份额

比例份额（proportional-share）调度程序有时也称公平份额（fair-share）调度程序，其核心思想为：**调度程序的最终目标是确保每个任务获得一定比例的 CPU 时间，而不是优化周转时间和响应时间**。

#### 彩票调度

彩票调度（lottery scheduling）是比例份额调度程序的一个优秀例子。基本思想为：每隔一段时间就举行一次彩票抽奖，以确定接下来应该运行哪个进程。越是应该频繁运行的进程，越是应该拥有更多赢得彩票的机会。

**彩票数（ticket）** 是彩票调度背后的基本概念，它代表了进程占有某个资源的份额。一个资源拥有的彩票数占总彩票数的百分比，就是它占有的资源的份额。通过不断地定时抽取彩票，彩票调度从 **概率** 上获得这种份额比例。

彩票调度最精彩的地方在于利用了 **随机性**。随机性至少有三点优势：

1. 随机方法常常可以避免各种奇怪的边界情况。
2. 随机方法很轻量，几乎不需要记录任何状态。
3. 随机方法很快，只要能产生随机数，就能做出决策。

彩票调度还提供了一些机制，它们以不同的方式来调度彩票：

1. 彩票货币（ticket currency）允许拥有一组彩票的用户以自己喜欢的方式将彩票分给不同的任务。之后操作系统再自动将这种货币兑换为正确的全局彩票。
2. 彩票转让（ticket transfer）。通过转让，一个进程可以临时将自己的彩票交给另一个进程，加速它的执行。
3. 彩票膨胀（ticket inflation）。利用膨胀，一个进程可以临时提升或降低自己拥有的彩票数量。一般用于进程间相互信任的环境。

由于随机性，彩票调度在任务执行时间很短时，公平度非常差。只有当任务执行的时间片非常多时，才能得出想要的结果。这也是基于概率的算法的一个通病。

#### 步长调度

步长调度（stride scheduling）解决了彩票调度的不确定性问题，它是一个确定性的公平分配算法。在步长调度中，每个任务都有自己的步长，这个值与彩票数量成反比。

对于每一个进程，每次运行后，让进程的计数器（称为行程（pass）值）增加它的步长那么多的增量，记录进程执行的总体进度。之后，调度程序使用进程的步长及行程值来确定调度哪个进程。基本思想很简单：当需要进行调度时，选择目前行程值最小的进程，运行它并在运行完之后将该进程的行程值增加一个步长。

#### Linux 的完全公平调度器

Linux 中的完全公平调度器（Completely Fair Scheduler，CFS）不仅实现了公平份额调度，还具有非常高的效率和可扩展性。CFS 的目标是：在所有相互竞争的进程之间公平地均匀分配 CPU。Linux 是通过 **virtual time (vruntime)** 技术来实现的。

每个进程运行时都会累计 vruntime 值。最常见的是，每个进程的 vruntime 都以相同的速率累积。当需要进行调度时，CFS 会选取具有最小 vruntime 值的进程运行。这里有一个需要考虑的点——调度器如何知道该在何时停止当前运行的进程并运行下一个进程？如果 CFS 切换得过于频繁，公平性增加而性能降低（更多的上下文切换），反之则公平性降低而性能增加（更少的上下文切换）。

CFS 具体是通过一些控制参数来管理调度过程的。第一个参数是 sched_latency，CFS 用它来决定一个进程在切换前应当运行的时长，通常为 48ms。CFS 用进程的数量 n 除 sched_latency 得到单个进程的时间片，从而确保完全公平。但是，如果进程过多怎么办？时间片会因此变得非常小吗？上下文切换会更加频繁吗？并不会，CFS 为了解决这个问题，给了我们另一个参数 min_granularity，这个值通常为 6ms。CFS 永远不会将时间片的大小设置为小于这个值的数。

CFS 还支持控制进程的优先级，允许用户赋予某些进程更高的 CPU 份额。这并不是通过彩票数实现的，而是通过 Linux 中经典的进程 nice 值实现的。对于一个进程而言，其 nice 值可以是 [-20 , +19] 之间的任一整数，默认为 0。正数表示更低的优先级，而负数表示更高的优先级。CFS 会将 nice 值映射为权重：

```c
static const int prio_to_weight[40] = { 
        /* -20 */ 88761, 71755, 56483, 46273, 36291, 
        /* -15 */ 29154, 23254, 18705, 14949, 11916, 
        /* -10 */ 9548, 7620, 6100, 4904, 3906, 
        /* -5 */ 3121, 2501, 1991, 1586, 1277, 
        /* 0 */ 1024, 820, 655, 526, 423, 
        /* 5 */ 335, 272, 215, 172, 137,
         /* 10 */ 110, 87, 70, 56, 45, 
        /* 15 */ 36, 29, 23, 18, 15, 
};
```

有了权重之后，我们就可以计算出每个进程的时间片

$$ time \underline{\ } slice_k = \frac {weight_k}{\sum_{i=0}^{n-1}(weight_i)} \cdot sched \underline{\ } latency $$

此外，vruntime 的计算方式也有所改变：

$$ vruntime_i = vruntime_i + \frac {weight_0}{weight_i} \cdot runtime_i $$

### 多处理器调度

> 关键问题：操作系统应该如何在多 CPU 上调度任务？会遇到什么新问题？已有技术是否依然适用？

#### 缓存

多处理器与单 CPU 之间最大的区别在于 **硬件对缓存（cache）的使用，以及多处理器之间共享数据的方式**：

![](/images/reading_notes/ostep/cpu-with-cache.png)

缓存是基于 **局部性（locality）** 的。局部性分为两种：

* 时间局部性：当一个数据被访问后，她很有可能在不久的将来再次被访问。
* 空间局部性：当程序访问某个地址的数据时，很有可能会紧接着访问该地址周围的数据。

缓存可以有效地提升数据的访问速度，从而加快程序的运行速度。CPU 会先尝试从缓存中查找数据，若缓存中没有需要的数据，则访问内存。由于数据更新的存在，所以在在多处理器中，会出现 **缓存一致性（cache coherence）问题**。

通过监控内存访问，硬件可以保证获得正确的数据，并保证共享内存的唯一性。在基于总线的系统中，一种方式就是使用总线窥探（bus snooping）。每个缓存都通过监听链接到所有缓存和内存的总线，来发现内存访问。如果 CPU 发现它放在缓存中的数据被更新了，就会作废（invalidate）本地的副本（从缓存中移除）或者更新它（修改会新的值）。

虽然缓存在一致性方面做了很多工作，但是应用程序还是需要关心共享数据的访问。跨 CPU 访问（尤其是写入）共享数据或数据结构时，需要使用 **互斥原语（比如锁）**，才能保证正确性。一些无锁的数据结构也能达到这个目的，但是它们非常复杂，使用得不是太多。同步操作对性能有影响，随着 CPU 数量的增加，访问同步共享的数据结构会变得很慢，因为需要做大量的同步操作。

多处理器调度中还需要考虑 **缓存亲和度（cache affinity）**：当进程在某个 CPU 上运行时，该 CPU 的缓存内会维护很多状态。若下次该进程还在同一个 CPU 上运行，它会由于缓存中的数据而执行得非常快。相反，在不同的 CPU 上执行同一个进程时，由于需要重新加载数据，所以会变得很慢。因此，最好是尽可能让同一个进程在同一个 CPU 上执行。

#### 多队列调度

有些系统采用了多队列的调度方案，比如每个 CPU 一个队列，称之为多队列多处理器调度（Multi-Queue Multiprocessor Scheduling，MQMS）。

在 MQMS 中，基本调度框架包含多个调度队列，每个队列可以使用不同的调度规则。当任务进入系统后，系统会按照一些启发性规则将其放入到某个调度队列。这样一来，每个 CPU 之间的调度相互独立，不需要同步。

MQMS 天生具有良好的缓存亲和度。所有的工作都保持在固定的 CPU 上，因而可以很好地利用缓存数据。但这又存在一个新的问题——**负载不均（load imbalance）**。

为了实现负载均衡。我们可以让任务跨 CPU 移动，这种技术被称为迁移（migration）。有很多种迁移模式，不过最棘手的部分就是如何决定发起迁移？有一个被称为 **工作窃取（work stealing）** 的技术，工作量较少的（源）队列不定期“偷看”其它（目标）队列的任务情况，如果目标队列更加拥挤，就从目标队列“窃取”一个或多个任务，实现负载均衡。在使用这种方法时，需要留意：对其它队列的检查不能太频繁，否则会带来较高的开销，但检查间隔又不能太长，否则可能带来严重的负载不均。所以需要找到合适的阈值。


#### Linux 上的多处理器调度

有趣的时，Linux 社区一直没有就构建多处理器调度成都达成共识。一直以来，存在三种不同的调度程序：

* O(1) 调度程序
* 完全公平调度程序（CFS）
* BF 调度程序（BFS）
O(1) 和 CFS 采用多队列，而 BFS 采用单队列。

有关 BFS 的更多信息：http://ck.kolivas.org/patches/bfs/bfs-faq.txt


